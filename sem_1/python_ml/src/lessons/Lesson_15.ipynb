{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1>Факультет \"Прикладная математика\" МАИ</h1>\n",
    "<h2>Курс \"Основы Python для анализа данных\"</h2>\n",
    "<h2>Артамонов Игорь Михайлович</h2>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Занятие № 15. Временные ряды и их анализ.</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общение / вопросы по курсу\n",
    "\n",
    "Платформа для групповой работы Atlassian Confluence факультета \"Прикладная математика\"\n",
    "\n",
    "https://mai.moscow/display/PYTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <b>Занятие № 15. Временные ряды и их анализ</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## virtualenv + Jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "<Ctrl> + <Alt> + T - новое окно терминала\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ conda -V\n",
    "\n",
    "$ conda update conda\n",
    "\n",
    "$ conda search \"^python$\"\n",
    "\n",
    "$ conda create -n yourenvname python=x.x anaconda\n",
    "\n",
    "$ source activate yourenvname\n",
    "\n",
    "$ jupyter notebook\n",
    "\n",
    "$ conda install -n yourenvname [package]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">ВОПРОС</a>\n",
    "Какие задачи машинного обучения для __временных рядов__ могут быть:\n",
    "* регрессией?\n",
    "* классификацией?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sc\n",
    "from scipy.stats import randint\n",
    "from numpy.random import randn\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib.patches import Ellipse\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import statsmodels.api as sm  \n",
    "from statsmodels.tsa.stattools import acf  \n",
    "from statsmodels.tsa.stattools import pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import train_test_split # to split the data into two parts\n",
    "from sklearn.model_selection import KFold # use for cross validation\n",
    "from sklearn.preprocessing import StandardScaler # for normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline # pipeline making\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import metrics # for the check the error and accuracy of the model\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "\n",
    "import sys\n",
    "import itertools\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv), data manipulation as in SQL\n",
    "import matplotlib.pyplot as plt # this is used for the plot the graph \n",
    "import seaborn as sns # used for plot interactive graph. \n",
    "\n",
    "## for Deep-learing:\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Dense, Embedding, LSTM, ConvLSTM2D, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD \n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Временной ряд\n",
    "* последовательно измеренные через некоторые (зачастую равные) промежутки времени данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Что из них можно извлечь__\n",
    "* что происходило (закономерности в прошлом)\n",
    "* влияющие факторы, особенно - связанные со временем\n",
    "* что будет происходить (предсказание будущего)\n",
    "\n",
    "__Обычно делят на:__\n",
    "* анализ в частотной области\n",
    "    - спектральный анализ / вейвлет-анализ\n",
    "    - хорошо подходит для предварительных исследований\n",
    "* анализ во временной области\n",
    "    - кросс-корреляционный анализ\n",
    "    - автокорреляционный анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Что с ними можно сделать__<br><br>\n",
    "__Общее исследование__\n",
    "* Визуальное изучение графических представлений временных рядов\n",
    "* Автокорреляционный анализ для изучения зависимостей\n",
    "* Спектральный анализ для изучения циклического поведения, не связанного с сезонностью<br><br>\n",
    "\n",
    "__Описание__\n",
    "* Разделение компонент: тренд, сезонность, медленно и быстро меняющиеся компоненты, циклическая нерегулярность\n",
    "* Простейшие свойства частных распределений<br><br>\n",
    "\n",
    "__Прогнозирование и предсказание__\n",
    "* Полноценные статистические модели при стохастическом моделировании для создания альтернативных версий временных рядов, показывающих, что могло бы случиться на произвольных отрезках времени в будущем (предсказание)\n",
    "* Упрощённые или поноценные статистические модели для описания вероятные значения временного ряда в ближайшем будущем при известных последних значениях (прогноз)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что нам будет полезно:\n",
    "* statsmodels - методы статистического моделирования\n",
    "* одномерные сверточные модели\n",
    "* рекуррентные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метод скользящих средних"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{y_t} = \\frac{1}{k} \\sum_{n=0}^{k-1} y_{t\\_n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Экспоненциальное сглаживание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одинарное: \n",
    "* учитываем исторические данные с экспоненциальным уменьшением их веса\n",
    "$$\n",
    "\\hat{y_t} = \\alpha \\cdot y_t + (1- \\alpha) \\cdot y_{t-1}\n",
    "$$<br>\n",
    "Двойное:<br><br>\n",
    "* добавляем уровень (level, intercept) и тренд (trend, slope)\n",
    "$$\n",
    "l_x = \\alpha y_x + (1 - \\alpha) (l_{x-1} + b_{x-1})\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "b_x = \\beta (l_x - l_{x-1}) + (1 - \\beta) b_{x-1}\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "\\hat{y_t} = l_x + b_x\n",
    "$$<br><br>\n",
    "Модель Холта-Винтерса:<br><br>\n",
    "* добавляем сезонность (повторяющиеся колебания вокруг уровня и тренда), которая характеризуется длиной сезона — периодом<br><br>\n",
    "$$\n",
    "l_x = \\alpha (y_x +  s_{x-L}) + (1 - \\alpha) (l_{x-1} + b_{x-1})\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "b_x = \\beta (l_x - l_{x-1}) + (1 - \\beta) b_{x-1}\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "s_x = \\gamma (y_x - l_x) + (1 - \\gamma) s_{x-L}\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "\\hat{y_t} = l_x + b_x\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA\n",
    "\n",
    "http://www.seanabu.com/2016/03/22/time-series-seasonal-ARIMA-model-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>A</b>uto<b>R</b>regression. A model that uses the dependent relationship between an observation and some number of lagged observations.<br>\n",
    "<b>I</b>ntegrated. The use of differencing of raw observations (e.g. subtracting an observation from an observation at the previous time step) in order to make the time series stationary.<br>\n",
    "<b>M</b>oving <b>A</b>verage. A model that uses the dependency between an observation and a residual error from a moving average model applied to lagged observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Стационарность__ - свойство процесса не менять своих статистических характеристик с течением времени, а именно постоянство матожидания, постоянство дисперсии (она же гомоскедастичность) и независимость ковариационной функции от времени (должна зависеть только от расстояния между наблюдениями)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Матожидание растет:\n",
    "<img src=\"images15/Mean_nonstationary.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Варьируется дисперсия:\n",
    "<img src=\"images15/Var_nonstationary.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Непостоянная ковариация:\n",
    "<img src=\"images15/Cov_nonstationary.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data15/portland-oregon-average-monthly-.csv', index_col=0)\n",
    "df.index.name=None\n",
    "df.reset_index(inplace=True)\n",
    "df.drop(df.index[114], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.strptime(\"1973-01-01\", \"%Y-%m-%d\")\n",
    "date_list = [start + relativedelta(months=x) for x in range(0,114)]\n",
    "df['index'] =date_list\n",
    "df.set_index(['index'], inplace=True)\n",
    "df.index.name=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns= ['riders']\n",
    "df['riders'] = df.riders.apply(lambda x: int(x)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.riders.plot(figsize=(12,8), title= 'Monthly Ridership', fontsize=14)\n",
    "plt.savefig('month_ridership.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition = seasonal_decompose(df.riders, freq=12)  \n",
    "fig = plt.figure()  \n",
    "fig = decomposition.plot()  \n",
    "fig.set_size_inches(15, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def test_stationarity(timeseries):\n",
    "    \n",
    "    #Determing rolling statistics\n",
    "    rolmean = timeseries.rolling(12).mean()\n",
    "    rolstd = timeseries.rolling(12).std()\n",
    "\n",
    "    #Plot rolling statistics:\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    orig = plt.plot(timeseries, color='blue',label='Original')\n",
    "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.show()\n",
    "    \n",
    "    #Perform Dickey-Fuller test:\n",
    "    print ('Results of Dickey-Fuller Test:')\n",
    "    dftest = adfuller(timeseries, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print (dfoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stationarity(df.riders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['riders_log']= df.riders.apply(lambda x: np.log(x))  \n",
    "test_stationarity(df.riders_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['first_difference'] = df.riders - df.riders.shift(1)  \n",
    "test_stationarity(df.first_difference.dropna(inplace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_first_difference'] = df.riders_log - df.riders_log.shift(1)  \n",
    "test_stationarity(df.log_first_difference.dropna(inplace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['seasonal_difference'] = df.riders - df.riders.shift(12)  \n",
    "test_stationarity(df.seasonal_difference.dropna(inplace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_seasonal_difference'] = df.riders_log - df.riders_log.shift(12)  \n",
    "test_stationarity(df.log_seasonal_difference.dropna(inplace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['seasonal_first_difference'] = df.first_difference - df.first_difference.shift(12)  \n",
    "test_stationarity(df.seasonal_first_difference.dropna(inplace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_seasonal_first_difference'] = df.log_first_difference - df.log_first_difference.shift(12)  \n",
    "test_stationarity(df.log_seasonal_first_difference.dropna(inplace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "fig = sm.graphics.tsa.plot_acf(df.seasonal_first_difference.iloc[13:], lags=40, ax=ax1)\n",
    "ax2 = fig.add_subplot(212)\n",
    "fig = sm.graphics.tsa.plot_pacf(df.seasonal_first_difference.iloc[13:], lags=40, ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = sm.tsa.statespace.SARIMAX(df.riders, trend='n', order=(0,1,0), seasonal_order=(0,1,1,12))\n",
    "results = mod.fit()\n",
    "print (results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = sm.tsa.statespace.SARIMAX(df.riders, trend='n', order=(0,1,0), seasonal_order=(1,1,1,12))\n",
    "results = mod.fit()\n",
    "print (results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['forecast'] = results.predict(start = 102, end= 114, dynamic= True)  \n",
    "df[['riders', 'forecast']].plot(figsize=(12, 8)) \n",
    "plt.savefig('ts_df_predict.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npredict =df.riders['1982'].shape[0]\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "npre = 12\n",
    "ax.set(title='Ridership', xlabel='Date', ylabel='Riders')\n",
    "ax.plot(df.index[-npredict-npre+1:], df.iloc[-npredict-npre+1:]['riders'], 'o', label='Observed')\n",
    "ax.plot(df.index[-npredict-npre+1:], df.iloc[-npredict-npre+1:]['forecast'], 'g', label='Dynamic forecast')\n",
    "legend = ax.legend(loc='lower right')\n",
    "legend.get_frame().set_facecolor('w')\n",
    "plt.savefig('ts_predict_compare.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сложности с ARIMA-моделями:\n",
    "* требуют много времени на подготовку данных\n",
    "* сложно настраивать\n",
    "* требуют частого переобучения на новых данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рекуррентные нейронные сети (RNN) - для временных рядов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* В традиционной NN предполагается, что все входы и выходы независимы друг от друга\n",
    "* Есть задачи, в которых есть зависимость между предыдущими и последующими данными\n",
    "* Основная идея - получить возможность работать с последовательной информацией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Lesson_14/images14/rnn.jpg\">\n",
    "A recurrent neural network and the unfolding in time of the computation involved in its forward computation. Source: Nature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение RNN производится с помощью алгоритма _обратного распространения через время_ (Backpropagation Through Time - __BPTT__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Lesson_14/images14/Backpropagation-Through-Time-BPTT-in-standard-BRNNs.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Lesson_14/images14/greff_lstm_diagram.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем:\n",
    "* dataset: https://www.kaggle.com/uciml/electric-power-consumption-data-set\n",
    "* kernel: https://www.kaggle.com/amirrezaeian/time-series-data-analysis-using-lstm-tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Set Information:\n",
    "\n",
    "This archive contains 2075259 measurements gathered in a house located in Sceaux (7km of Paris, France) between December 2006 and November 2010 (47 months). \n",
    "Notes: \n",
    "<ol>\n",
    "<li>(global_active_power*1000/60 - sub_metering_1 - sub_metering_2 - sub_metering_3) represents the active energy consumed every minute (in watt hour) in the household by electrical equipment not measured in sub-meterings 1, 2 and 3. \n",
    "<li>The dataset contains some missing values in the measurements (nearly 1,25% of the rows). All calendar timestamps are present in the dataset but for some timestamps, the measurement values are missing: a missing value is represented by the absence of value between two consecutive semi-colon attribute separators. For instance, the dataset shows missing values on April 28, 2007.\n",
    "</ol>\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "<ol>\n",
    "<li>date: Date in format dd/mm/yyyy \n",
    "<li>time: time in format hh:mm:ss \n",
    "<li>global_active_power: household global minute-averaged active power (in kilowatt) \n",
    "<li>global_reactive_power: household global minute-averaged reactive power (in kilowatt) \n",
    "<li>voltage: minute-averaged voltage (in volt) \n",
    "<li>global_intensity: household global minute-averaged current intensity (in ampere) \n",
    "<li>sub_metering_1: energy sub-metering No. 1 (in watt-hour of active energy). It corresponds to the kitchen, containing mainly a dishwasher, an oven and a microwave (hot plates are not electric but gas powered). \n",
    "<li>sub_metering_2: energy sub-metering No. 2 (in watt-hour of active energy). It corresponds to the laundry room, containing a washing-machine, a tumble-drier, a refrigerator and a light. \n",
    "<li>sub_metering_3: energy sub-metering No. 3 (in watt-hour of active energy). It corresponds to an electric water-heater and an air-conditioner.\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data15/household_power_consumption.txt', sep=';',\n",
    "                 parse_dates={'dt' : ['Date', 'Time']}, infer_datetime_format=True,\n",
    "                 low_memory=False, na_values=['nan','?'], index_col='dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заменяем nan на средние по колонкам\n",
    "for j in range(0,7):        \n",
    "        df.iloc[:,j]=df.iloc[:,j].fillna(df.iloc[:,j].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем, что не осталось нулевых значений\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Global_active_power.resample('D').sum().plot(title='Global_active_power resampled over day for sum') \n",
    "plt.tight_layout()\n",
    "plt.show()   \n",
    "\n",
    "df.Global_active_power.resample('D').mean().plot(title='Global_active_power resampled over day for mean', color='red') \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">ВОПРОС</font>\n",
    "Видите ли Вы здесь аномалии?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = df.Global_intensity.resample('D').agg(['mean', 'std'])\n",
    "r.plot(subplots = True, title='Global_intensity resampled over day')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Global_active_power'].resample('M').mean().plot(kind='bar')\n",
    "plt.xticks(rotation=60)\n",
    "plt.ylabel('Global_active_power')\n",
    "plt.title('Global_active_power per month (averaged over month)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Global_active_power'].resample('Q').mean().plot(kind='bar')\n",
    "plt.xticks(rotation=60)\n",
    "plt.ylabel('Global_active_power')\n",
    "plt.title('Global_active_power per quarter (averaged over quarter)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Voltage'].resample('M').mean().plot(kind='bar', color='red')\n",
    "plt.xticks(rotation=60)\n",
    "plt.ylabel('Voltage')\n",
    "plt.title('Voltage per quarter (summed over quarter)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sub_metering_1'].resample('M').mean().plot(kind='bar', color='brown')\n",
    "plt.xticks(rotation=60)\n",
    "plt.ylabel('Sub_metering_1')\n",
    "plt.title('Sub_metering_1 per quarter (summed over quarter)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below I compare the mean of different featuresre sampled over day. \n",
    "# specify columns to plot\n",
    "cols = [0, 1, 2, 3, 5, 6]\n",
    "i = 1\n",
    "groups=cols\n",
    "values = df.resample('D').mean().values\n",
    "# plot each column\n",
    "plt.figure(figsize=(15, 10))\n",
    "for group in groups:\n",
    "    plt.subplot(len(cols), 1, i)\n",
    "    plt.plot(values[:, group])\n",
    "    plt.title(df.columns[group], y=0.75, loc='right')\n",
    "    i += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Global_reactive_power.resample('W').mean().plot(color='y', legend=True)\n",
    "df.Global_active_power.resample('W').mean().plot(color='r', legend=True)\n",
    "df.Sub_metering_1.resample('W').mean().plot(color='b', legend=True)\n",
    "df.Global_intensity.resample('W').mean().plot(color='g', legend=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Global_active_power.resample('M').mean().plot(kind='hist', bins=30, color='r', legend=True )\n",
    "df.Global_reactive_power.resample('M').mean().plot(kind='hist', bins=30, color='b', legend=True)\n",
    "\n",
    "df.Global_intensity.resample('M').mean().plot(kind='hist', bins=30, color='g', legend=True)\n",
    "df.Sub_metering_1.resample('M').mean().plot(kind='hist', bins=30, color='y', legend=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Voltage.resample('M').sum().plot(kind='hist',color='g', legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_returns = df.pct_change()\n",
    "sns.jointplot(x='Global_intensity', y='Global_active_power', data=data_returns)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='Voltage', y='Global_active_power', data=data_returns)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(df.corr(method='spearman'),vmax=1,vmin=-1,cmap='PRGn')\n",
    "plt.title('without resampling', size=15)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(df.resample('M').mean().corr(method='spearman'),vmax=1,vmin=-1,cmap='PRGn')\n",
    "plt.title('resampled over month', size=15)\n",
    "plt.colorbar()\n",
    "plt.margins(0.02)\n",
    "plt.matshow(df.resample('A').mean().corr(method='spearman'),vmax=1,vmin=-1,cmap='PRGn')\n",
    "plt.title('resampled over year', size=15)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    dff = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(dff.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(dff.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## resampling of data over hour\n",
    "df_resample = df.resample('h').mean() \n",
    "df_resample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If you would like to train based on the resampled data (over hour), then used below\n",
    "values = df_resample.values \n",
    "\n",
    "## full data without resampling\n",
    "#values = df.values\n",
    "\n",
    "# integer encode direction\n",
    "# ensure all data is float\n",
    "#values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[8,9,10,11,12,13]], axis=1, inplace=True)\n",
    "print(reframed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "\n",
    "n_train_time = 365*24\n",
    "train = values[:n_train_time, :]\n",
    "test = values[n_train_time:, :]\n",
    "##test = values[n_train_time:n_test_time, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape) \n",
    "# We reshaped the input into the 3D format as expected by LSTMs, namely [samples, timesteps, features]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Архитектура модели__\n",
    "<ol>\n",
    "<li>LSTM с 100 нейронами в первом видимом слое\n",
    "<li>dropout 20%\n",
    "<li>1 нейрон в выходном слое для предсказания  Global_active_power.\n",
    "<li>Входные данные - 1 временной шаг с 7 переменными (features).\n",
    "<li>Mean Absolute Error (MAE) loss function\n",
    "<li>Adam version of stochastic gradient descent.\n",
    "<li>The model will be fit for 20 training epochs with a batch size of 70.\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "#    model.add(LSTM(70))\n",
    "#    model.add(Dropout(0.3))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=20, batch_size=70, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], 7))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = np.concatenate((yhat, test_X[:, -6:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = np.concatenate((test_y, test_X[:, -6:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## time steps, every step is one hour (you can easily convert the time step to the actual time index)\n",
    "## for a demonstration purpose, I only compare the predictions in 200 hours. \n",
    "\n",
    "aa=[x for x in range(200)]\n",
    "plt.plot(aa, inv_y[:200], marker='.', label=\"actual\")\n",
    "plt.plot(aa, inv_yhat[:200], 'r', label=\"prediction\")\n",
    "plt.ylabel('Global_active_power', size=15)\n",
    "plt.xlabel('Time step', size=15)\n",
    "plt.legend(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/Prakashvanapalli/TensorFlow/blob/master/Blogposts/Backpropogation_with_Images.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Экзаменационные вопросы:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Временные ряды"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
